{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model for the planet dataset\n",
    "import sys\n",
    "from numpy import load\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY = load_dataset()\n",
    "# create data generator\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "# prepare iterators\n",
    "train_it = datagen.flow(trainX, trainY, batch_size=128)\n",
    "test_it = datagen.flow(testX, testY, batch_size=128)\n",
    "# define model\n",
    "model = define_model()\n",
    "# fit model\n",
    "history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "    validation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=0)\n",
    "# evaluate model\n",
    "loss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "print('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "# learning curves\n",
    "summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\tdata = load('planet_data.npz')\n",
    "\tX, y = data['arr_0'], data['arr_1']\n",
    "\t# separate into train and test datasets\n",
    "\ttrainX, testX, trainY, testY = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\tprint(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# calculate fbeta score for multi-class/label classification\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "\t# clip predictions\n",
    "\ty_pred = backend.clip(y_pred, 0, 1)\n",
    "\t# calculate elements\n",
    "\ttp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "\tfp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "\tfn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\t# calculate precision\n",
    "\tp = tp / (tp + fp + backend.epsilon())\n",
    "\t# calculate recall\n",
    "\tr = tp / (tp + fn + backend.epsilon())\n",
    "\t# calculate fbeta, averaged across each class\n",
    "\tbb = beta ** 2\n",
    "\tfbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "\treturn fbeta_score\n",
    "\n",
    "# define cnn model\n",
    "def define_model(in_shape=(128, 128, 3), out_shape=17):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(out_shape, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "\treturn model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Fbeta')\n",
    "\tpyplot.plot(history.history['fbeta'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_fbeta'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = datagen.flow(trainX, trainY, batch_size=128)\n",
    "\ttest_it = datagen.flow(testX, testY, batch_size=128)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=0)\n",
    "\t# evaluate model\n",
    "\tloss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
