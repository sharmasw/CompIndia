{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import dateutil\n",
    "from sklearn import ensemble,metrics,linear_model,tree\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campData=pd.read_csv('campaign_data.csv')\n",
    "coupon_item_mappingData=pd.read_csv('coupon_item_mapping.csv')\n",
    "customer_demographicsData=pd.read_csv('customer_demographics.csv')\n",
    "c_trans_Data=pd.read_csv('customer_transaction_data.csv')\n",
    "item_dataData=pd.read_csv('item_data.csv')\n",
    "trainData=pd.read_csv('train.csv')\n",
    "test_QyjYwdjData=pd.read_csv('test_QyjYwdj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['dtType']='train'\n",
    "test_QyjYwdjData['dtType']='test'\n",
    "\n",
    "allData=trainData.append(test_QyjYwdjData,sort=False)\n",
    "allData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['redemption_status'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campData['start_date']=campData['start_date'].apply(lambda x: dateutil.parser.parse(x,dayfirst=True))\n",
    "campData['end_date']=campData['end_date'].apply(lambda x: dateutil.parser.parse(x,dayfirst=True))\n",
    "campData['duration']=campData['end_date']-campData['start_date']\n",
    "campData['duration']=campData['duration'].apply(lambda x: x.days)\n",
    "campData['start_Month']=campData['start_date'].apply(lambda x: x.month)\n",
    "campData['end_Month']=campData['end_date'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_trans_Data['date']=c_trans_Data['date'].apply(lambda x: dateutil.parser.parse(x,dayfirst=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (max(c_trans_Data['date']),min(c_trans_Data['date']))\n",
    "print (max(campData['start_date']),min(campData['start_date']))\n",
    "print (max(campData['end_date']),min(campData['end_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "campData.sort_values('start_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,k,l in tqdm(zip(campData['start_date'],campData['end_date'],campData['campaign_id'])):\n",
    "    c_trans_Data['campaign_'+str(l).zfill(2)]=c_trans_Data['date'].apply(lambda x:1 if ((x >= j) & (x <= k)) else 0)\n",
    "#     if (c_trans_Data['date'][1324561] >= j) & (c_trans_Data['date'][1324561] <= k):\n",
    "#         print (j,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campCol=['campaign_24', 'campaign_25',\n",
    "       'campaign_20', 'campaign_23', 'campaign_21', 'campaign_22',\n",
    "       'campaign_18', 'campaign_19', 'campaign_17', 'campaign_16',\n",
    "       'campaign_13', 'campaign_11', 'campaign_12', 'campaign_10',\n",
    "       'campaign_09', 'campaign_08', 'campaign_07', 'campaign_06',\n",
    "       'campaign_03', 'campaign_05', 'campaign_04', 'campaign_01',\n",
    "       'campaign_02', 'campaign_30', 'campaign_29', 'campaign_28',\n",
    "       'campaign_27', 'campaign_26']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campTran=c_trans_Data[campCol]\n",
    "\n",
    "campTran.iloc[1324544][campTran.iloc[1324544]==1].index\n",
    "\n",
    "campTran['campParticipated']=campTran.apply(lambda x: x[x==1].index.values, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_trans_Data['campParticipated']=campTran['campParticipated']\n",
    "c_trans_Data['filt']=c_trans_Data['campParticipated'].apply(lambda x: len(x))\n",
    "for j in campCol:\n",
    "    del c_trans_Data[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_trans_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_trans_Data=c_trans_Data[c_trans_Data['filt']!=0]\n",
    "c_trans_Data['campaign_id']=c_trans_Data['campParticipated'].apply(lambda x: int(x[0].split('_')[1]))\n",
    "del c_trans_Data['filt']\n",
    "del c_trans_Data['campParticipated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedData=pd.merge(c_trans_Data,campData,on='campaign_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedData['occurenceofPurch']=mergedData['date']-mergedData['start_date']\n",
    "mergedData['occurenceofPurch']=mergedData['occurenceofPurch'].apply(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bohotData=pd.merge(mergedData,coupon_item_mappingData,on='item_id',how='left')\n",
    "# bohotData=pd.merge(bohotData,campData,on='item_id',how='left')\n",
    "bohotData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itenACoupData=pd.merge(coupon_item_mappingData,item_dataData,on='item_id',how='left').sort_values('coupon_id')\n",
    "itemInfoFromTransaction=c_trans_Data.groupby('item_id',as_index=False).agg({'selling_price':'mean',\n",
    "                                                                     'coupon_discount':{'discountCount':'count','totalDisc':'sum'},\n",
    "                                                                    'other_discount':{'OTdiscountCount':'count','OTtotalDisc':'sum'}})\n",
    "itemInfoFromTransaction.columns=[''.join(j) for j in itemInfoFromTransaction.columns]\n",
    "\n",
    "itenACoupData=pd.merge(coupon_item_mappingData,item_dataData,on='item_id',how='left').sort_values('coupon_id')\n",
    "\n",
    "itemInfoFromTransaction['dicountPerGiven']=abs(itemInfoFromTransaction['coupon_discounttotalDisc']/itemInfoFromTransaction['coupon_discountdiscountCount'])\n",
    "itemInfoFromTransaction['dicountOthPerGiven']=abs(itemInfoFromTransaction['other_discountOTtotalDisc']/itemInfoFromTransaction['other_discountOTdiscountCount'])\n",
    "itemInfoFromTransaction['dicountGivenPerc']=abs(itemInfoFromTransaction['dicountPerGiven']/itemInfoFromTransaction['selling_pricemean'])\n",
    "itemInfoFromTransaction['dicountOthPerGivenPerc']=abs(itemInfoFromTransaction['dicountOthPerGiven']/itemInfoFromTransaction['selling_pricemean'])\n",
    "\n",
    "\n",
    "transItemData=pd.merge(c_trans_Data,item_dataData,on='item_id',how='left')\n",
    "transItemData.shape\n",
    "\n",
    "transItemData['coupon_discountAvail']=transItemData['coupon_discount'].apply(lambda x: 1 if x !=0 else 0)\n",
    "\n",
    "itemCouponDetail=transItemData.groupby('item_id',as_index=False).agg({'coupon_discountAvail':{'sumOFCoupon':'sum','totalCount':'count'}})\n",
    "itemCouponDetail.columns=[''.join(jj) for jj in itemCouponDetail.columns]\n",
    "itemCouponDetail['probaItem']=itemCouponDetail['coupon_discountAvailsumOFCoupon']/itemCouponDetail['coupon_discountAvailtotalCount']\n",
    "# itemCouponDetail[itemCouponDetail['probaItem']>0]\n",
    "\n",
    "mergedItemCoupon=pd.merge(itenACoupData,itemInfoFromTransaction,on='item_id',how='left').fillna(0)\n",
    "mergedItemCoupon=pd.merge(mergedItemCoupon,itemCouponDetail[['item_id','probaItem']],on='item_id',how='left').fillna(0)\n",
    "#some  null values present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatoCluster=mergedItemCoupon.groupby('coupon_id',as_index=False).mean()[['coupon_id', \n",
    "       'selling_pricemean', 'coupon_discountdiscountCount',\n",
    "       'coupon_discounttotalDisc', 'other_discountOTdiscountCount',\n",
    "       'other_discountOTtotalDisc', 'dicountPerGiven', 'dicountOthPerGiven',\n",
    "       'dicountGivenPerc', 'dicountOthPerGivenPerc','probaItem']]\n",
    "\n",
    "clusVar=['coupon_id', \n",
    "       'selling_pricemean', 'coupon_discountdiscountCount',\n",
    "       'coupon_discounttotalDisc', 'other_discountOTdiscountCount',\n",
    "       'other_discountOTtotalDisc', 'dicountPerGiven', 'dicountOthPerGiven',\n",
    "       'dicountGivenPerc', 'dicountOthPerGivenPerc','probaItem']\n",
    "\n",
    "from sklearn import preprocessing,cluster,decomposition\n",
    "\n",
    "preProCl=preprocessing.StandardScaler()\n",
    "clusData=preProCl.fit_transform(datatoCluster[clusVar])\n",
    "\n",
    "pcaComp=decomposition.PCA()\n",
    "pcaData=pcaComp.fit_transform(clusData)\n",
    "pcaComp.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaDataFToGraph=pd.DataFrame(pcaData[:,:2],columns=['pca1','pca2'])\n",
    "kM=cluster.KMeans()\n",
    "pcaDataFToGraph['clusCat']=kM.fit_predict(clusData[:,:5])\n",
    "pcaDataFToGraph.head(2)\n",
    "sns.scatterplot(pcaDataFToGraph['pca1'],pcaDataFToGraph['pca2'],hue=pcaDataFToGraph['clusCat'])\n",
    "\n",
    "pcaDataTOCoup=pd.concat([datatoCluster[['coupon_id']],pcaDataFToGraph],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaDataTOCoup.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaDataTOCoup.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coupon Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupon_categFind=mergedItemCoupon.groupby(['coupon_id','category','brand','brand_type'],as_index=False).count()[['coupon_id','category','brand','brand_type','item_id']]\n",
    "couponProbItemCoup=mergedItemCoupon.groupby('coupon_id',as_index=False).agg({'probaItem':'mean'})\n",
    "coupon_categFind=coupon_categFind.sort_values(['coupon_id','item_id'],ascending=False)\n",
    "coupon_categFind=coupon_categFind.drop_duplicates('coupon_id')\n",
    "coupon_categFind=pd.merge(coupon_categFind,couponProbItemCoup,on='coupon_id',how='left')\n",
    "del coupon_categFind['item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupon_categFind.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureGener(df,indCol,fCol):\n",
    "    groupedMerge=df.groupby(indCol)\n",
    "    c_data={}\n",
    "    for c_id,tempT in  groupedMerge:\n",
    "        c_data[c_id]={}\n",
    "        c_data[c_id][indCol+fCol+'_max']=max(tempT[fCol])\n",
    "        c_data[c_id][indCol+fCol+'_min']=min(tempT[fCol])\n",
    "        c_data[c_id][indCol+fCol+'_mean']=np.mean(tempT[fCol])\n",
    "        c_data[c_id][indCol+fCol+'_75perc']=np.percentile(tempT[fCol],75)\n",
    "        c_data[c_id][indCol+fCol+'_25perc']=np.percentile(tempT[fCol],25)\n",
    "    tempDF=pd.DataFrame(c_data).transpose()\n",
    "    tempDF.columns=[indCol+fCol+'_max',indCol+fCol+'_min',indCol+fCol+'_mean',indCol+fCol+'_75perc',indCol+fCol+'_25perc']\n",
    "    return tempDF,tempDF.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantityCData,indexC=getFeatureGener(mergedData,'customer_id','quantity')\n",
    "selling_priceCData,indexC=getFeatureGener(mergedData,'customer_id','selling_price')\n",
    "other_discountCData,indexC=getFeatureGener(mergedData,'customer_id','other_discount')\n",
    "coupon_discountCData,indexC=getFeatureGener(mergedData,'customer_id','coupon_discount')\n",
    "occurenceofPurchCData,indexC=getFeatureGener(mergedData,'customer_id','occurenceofPurch')\n",
    "\n",
    "featureCustomerData=pd.concat([quantityCData,selling_priceCData,other_discountCData,coupon_discountCData,occurenceofPurchCData],axis=1)\n",
    "\n",
    "featureCustomerData=featureCustomerData.reset_index()\n",
    "featureCustomerData.columns=['customer_id']+list(featureCustomerData.columns[1:])\n",
    "\n",
    "featureCustomerData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantityIData,indexI=getFeatureGener(mergedData,'item_id','quantity')\n",
    "# selling_priceIData,indexI=getFeatureGener(mergedData,'item_id','selling_price')\n",
    "# other_discountIData,indexI=getFeatureGener(mergedData,'item_id','other_discount')\n",
    "# coupon_discountIData,indexI=getFeatureGener(mergedData,'item_id','coupon_discount')\n",
    "# occurenceofPurchIData,indexI=getFeatureGener(mergedData,'item_id','occurenceofPurch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itemFeatureData=pd.concat([quantityIData,selling_priceIData,other_discountIData,coupon_discountIData,occurenceofPurchIData],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itemFeatureData=itemFeatureData.reset_index()\n",
    "# itemFeatureData.columns=['item_id']+list(itemFeatureData.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bohotData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantityCPData,indexCP=getFeatureGener(bohotData,'coupon_id','quantity')\n",
    "selling_priceCPData,indexCP=getFeatureGener(bohotData,'coupon_id','selling_price')\n",
    "other_discountCPData,indexCP=getFeatureGener(bohotData,'coupon_id','other_discount')\n",
    "coupon_discountCPData,indexCP=getFeatureGener(bohotData,'coupon_id','coupon_discount')\n",
    "occurenceofPurchCPData,indexCP=getFeatureGener(bohotData,'coupon_id','occurenceofPurch')\n",
    "\n",
    "couponFeatureData=pd.concat([quantityCPData,selling_priceCPData,other_discountCPData,coupon_discountCPData,occurenceofPurchCPData],axis=1)\n",
    "\n",
    "couponFeatureData=couponFeatureData.reset_index()\n",
    "couponFeatureData.columns=['coupon_id']+list(couponFeatureData.columns[1:])\n",
    "\n",
    "couponFeatureData.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge traindata with Campdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X1=pd.merge(allData,featureCustomerData,on='customer_id',how='left')\n",
    "X1=pd.merge(X1,couponFeatureData,on='coupon_id',how='left')\n",
    "X1=pd.merge(X1,campData,on='campaign_id',how='left')\n",
    "X1=pd.merge(X1,customer_demographicsData,on='customer_id',how='left')\n",
    "X1=pd.merge(X1,pcaDataTOCoup,on='coupon_id',how='left')\n",
    "X1=pd.merge(X1,coupon_categFind,on='coupon_id',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5=X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5['marital_status']=X5['marital_status'].fillna('Other')\n",
    "X5['rented']=X5['rented'].fillna(0)\n",
    "X5['no_of_children']=X5['no_of_children'].fillna('0')\n",
    "X5['age_range']=X5['age_range'].fillna('Other')\n",
    "X5['family_size']=X5['family_size'].fillna('9999')\n",
    "X5['income_bracket']=X5['income_bracket'].fillna(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing,model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llP=preprocessing.LabelEncoder()\n",
    "# X5[jj]=llP.fit_transform(X5['campaign_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoColumns=['age_range', 'marital_status', 'rented', 'family_size','category', 'brand_type',\n",
    "       'no_of_children', 'income_bracket','campaign_type']+['clusCat']\n",
    "X5[categoColumns].head(2)#category\tbrand\tbrand_type\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5['income_bracket']=X5['income_bracket'].map(str)\n",
    "X5['no_of_children']=X5['no_of_children'].map(str)\n",
    "X5['clusCat']=X5['clusCat'].map(str)\n",
    "X5['rented']=X5['rented'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(X5['family_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "catData=pd.get_dummies(X5[categoColumns],prefix_sep='_',)\n",
    "# for jj in categoColumns:\n",
    "#     print (jj)\n",
    "#     llP=preprocessing.LabelEncoder()\n",
    "#     X5[jj]=llP.fit_transform(X5[jj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtData=pd.concat([X5,catData],sort=False,axis=1)\n",
    "# newtData=X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XVar=list(newtData.columns)\n",
    "XVar.remove('id')\n",
    "XVar.remove('redemption_status')\n",
    "XVar.remove('dtType')\n",
    "XVar.remove('start_date')\n",
    "XVar.remove('end_date')\n",
    "YVar='redemption_status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in categoColumns:#['campaign_id', 'coupon_id', 'customer_id']:\n",
    "    XVar.remove(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPart=newtData[newtData['dtType']=='train']\n",
    "testPart=newtData[newtData['dtType']=='test']\n",
    "trainPart.shape,testPart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection,metrics\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \tif feature_names is not None:\n",
    "# \t\tcreate_feature_map(feature_names)\n",
    "# \t\tmodel.dump_model('xgbmodel.txt', 'xgb.fmap', with_stats=True)\n",
    "# \t\timportance = model.get_fscore(fmap='xgb.fmap')\n",
    "# \t\timportance = sorted(importance.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# \t\timp_df = pd.DataFrame(importance, columns=['feature','fscore'])\n",
    "# \t\timp_df['fscore'] = imp_df['fscore'] / imp_df['fscore'].sum()\n",
    "# \t\timp_df.to_csv(\"imp_feat.txt\", index=False)\n",
    "\n",
    "# \tpred_test_y = model.predict(xgtest, ntree_limit=model.best_ntree_limit)\n",
    "# \tpred_test_y2 = model.predict(xgb.DMatrix(test_X2), ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "# \tloss = 0\n",
    "# \tif test_y is not None:\n",
    "# \t\tloss = metrics.roc_auc_score(test_y, pred_test_y)\n",
    "# \t\treturn pred_test_y, loss, pred_test_y2\n",
    "# \telse:\n",
    "# \t\treturn pred_test_y, loss, pred_test_y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test Split Train, Val, Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,testHX,trainY,testHY=model_selection.train_test_split(trainPart[XVar],trainPart[YVar],test_size=.2,stratify =trainPart[YVar])\n",
    "trainX.shape,testHX.shape,trainY.shape,testHY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX1,valX1,trainY1,valY1=model_selection.train_test_split(trainX,trainY,test_size=.2,stratify =trainY)\n",
    "trainX1.shape,valX1.shape,trainY1.shape,valY1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(trainX1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def runXGB(train_X, train_y, test_X, test_y=None, test_X2=None, feature_names=None, seed_val=0, rounds=500, dep=8, eta=0.05):\n",
    "params = {}\n",
    "params[\"objective\"] = \"binary:logistic\"\n",
    "params['eval_metric'] = 'auc'\n",
    "params[\"eta\"] = .05\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"min_child_weight\"] = 1\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"max_depth\"] = 8\n",
    "\n",
    "params[\"silent\"] = 1\n",
    "params[\"seed\"] = 200\n",
    "#params[\"max_delta_step\"] = 2\n",
    "#params[\"gamma\"] = 0.5\n",
    "num_rounds = 500\n",
    "\n",
    "plst = list(params.items())\n",
    "xgtrain = xgb.DMatrix(trainX1, label=trainY1)\n",
    "\n",
    "# if test_y is not None:\n",
    "xgtest = xgb.DMatrix(valX1, label=valY1)\n",
    "watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=100, verbose_eval=20)\n",
    "# else:\n",
    "#     xgtest = xgb.DMatrix(test_X)\n",
    "#     model = xgb.train(plst, xgtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=model.predict(xgtrain)\n",
    "t2=model.predict(xgtest)\n",
    "xgTest2 = xgb.DMatrix(testHX)\n",
    "t3=model.predict(xgTest2)\n",
    "\n",
    "# trainScore=modelR.predict_proba(trainX)\n",
    "# testScore=modelR.predict_proba(valX1)\n",
    "# test2Score=modelR.predict_proba(testHX)\n",
    "\n",
    "print ('train {} vs {} validation {} vs {} test {} vs {}'.format(sum(trainY),sum(t1),sum(valY1),sum(t2), sum(testHY),sum(t3)))\n",
    "metrics.roc_auc_score(trainY1,t1),metrics.roc_auc_score(valY1,t2),metrics.roc_auc_score(testHY,t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plst = list(params.items())\n",
    "xgtrain = xgb.DMatrix(trainPart[XVar],label=trainPart[YVar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = xgb.train(plst, xgtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgTestData = xgb.DMatrix(testPart[XVar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3Score=model.predict(xgTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testFScore=modelR.predict_proba(testPart[XVar])[:,1]\n",
    "firstSub2=pd.DataFrame(data={'id':test_QyjYwdjData['id'],YVar:t3Score})\n",
    "firstSub2.to_csv('xgbSub7.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
