{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import dateutil\n",
    "from sklearn import ensemble,metrics,linear_model,tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "campData=pd.read_csv('campaign_data.csv')\n",
    "coupon_item_mappingData=pd.read_csv('coupon_item_mapping.csv')\n",
    "customer_demographicsData=pd.read_csv('customer_demographics.csv')\n",
    "c_trans_Data=pd.read_csv('customer_transaction_data.csv')\n",
    "item_dataData=pd.read_csv('item_data.csv')\n",
    "trainData=pd.read_csv('train.csv')\n",
    "test_QyjYwdjData=pd.read_csv('test_QyjYwdj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128595, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData['dtType']='train'\n",
    "test_QyjYwdjData['dtType']='test'\n",
    "\n",
    "allData=trainData.append(test_QyjYwdjData,sort=False)\n",
    "allData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_transaction_dataData['TransactionAmt_to_mean_card1'] = train['selling_price'] / train.groupby(['card1'])['TransactionAmt'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>redemption_status</th>\n",
       "      <th>dtType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>1053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>116</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  campaign_id  coupon_id  customer_id  redemption_status dtType\n",
       "0   1           13         27         1053                0.0  train\n",
       "1   2           13        116           48                0.0  train"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature in  Camp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campData['start_date']=campData['start_date'].apply(lambda x: dateutil.parser.parse(x,dayfirst=True))\n",
    "campData['end_date']=campData['end_date'].apply(lambda x: dateutil.parser.parse(x,dayfirst=True))\n",
    "campData['duration']=campData['end_date']-campData['start_date']\n",
    "campData['duration']=campData['duration'].apply(lambda x: x.days)\n",
    "campData['start_Month']=campData['start_date'].apply(lambda x: x.month)\n",
    "campData['end_Month']=campData['end_date'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customer previous campaign reaction\n",
    "# item data transaction data merged4\n",
    "# train data and camp data merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge transaction data and Item data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transItemData=pd.merge(c_trans_Data,item_dataData,on='item_id',how='left')\n",
    "transItemData.shape\n",
    "\n",
    "transItemData['coupon_discountAvail']=transItemData['coupon_discount'].apply(lambda x: 1 if x !=0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transItemData.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itemCouponDetail=transItemData.groupby('item_id',as_index=False).agg({'coupon_discountAvail':{'sumOFCoupon':'sum','totalCount':'count'}})\n",
    "itemCouponDetail.columns=[''.join(jj) for jj in itemCouponDetail.columns]\n",
    "itemCouponDetail['probaItem']=itemCouponDetail['coupon_discountAvailsumOFCoupon']/itemCouponDetail['coupon_discountAvailtotalCount']\n",
    "# itemCouponDetail[itemCouponDetail['probaItem']>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge traindata with Campdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCampDatamerge=pd.merge(trainData,campData,on='campaign_id',how='left')\n",
    "trainCampDatamerge.shape,trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCampDatamerge.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engg in coupon mapping data and item data and transaction data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge mapping dtaa and transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itenACoupData=pd.merge(coupon_item_mappingData,item_dataData,on='item_id',how='left').sort_values('coupon_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itenACoupData.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature from transaction data Item level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemInfoFromTransaction=c_trans_Data.groupby('item_id',as_index=False).agg({'selling_price':'mean',\n",
    "                                                                     'coupon_discount':{'discountCount':'count','totalDisc':'sum'},\n",
    "                                                                    'other_discount':{'OTdiscountCount':'count','OTtotalDisc':'sum'}})\n",
    "itemInfoFromTransaction.columns=[''.join(j) for j in itemInfoFromTransaction.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemInfoFromTransaction['dicountPerGiven']=abs(itemInfoFromTransaction['coupon_discounttotalDisc']/itemInfoFromTransaction['coupon_discountdiscountCount'])\n",
    "itemInfoFromTransaction['dicountOthPerGiven']=abs(itemInfoFromTransaction['other_discountOTtotalDisc']/itemInfoFromTransaction['other_discountOTdiscountCount'])\n",
    "itemInfoFromTransaction['dicountGivenPerc']=abs(itemInfoFromTransaction['dicountPerGiven']/itemInfoFromTransaction['selling_pricemean'])\n",
    "itemInfoFromTransaction['dicountOthPerGivenPerc']=abs(itemInfoFromTransaction['dicountOthPerGiven']/itemInfoFromTransaction['selling_pricemean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemInfoFromTransaction.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itenACoupData.shape,itemInfoFromTransaction.shape,coupon_item_mappingData.shape,item_dataData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itenACoupData.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge item information from transaction to coupon item information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedItemCoupon=pd.merge(itenACoupData,itemInfoFromTransaction,on='item_id',how='left').fillna(0)\n",
    "mergedItemCoupon=pd.merge(mergedItemCoupon,itemCouponDetail[['item_id','probaItem']],on='item_id',how='left').fillna(0)\n",
    "#some  null values present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedItemCoupon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupon_categFind=mergedItemCoupon.groupby(['coupon_id','category','brand','brand_type'],as_index=False).count()[['coupon_id','category','brand','brand_type','item_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couponProbItemCoup=mergedItemCoupon.groupby('coupon_id',as_index=False).agg({'probaItem':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupon_categFind=coupon_categFind.sort_values(['coupon_id','item_id'],ascending=False)\n",
    "coupon_categFind=coupon_categFind.drop_duplicates('coupon_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupon_categFind=pd.merge(coupon_categFind,couponProbItemCoup,on='coupon_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del coupon_categFind['item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupon_categFind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedItemCoupon[mergedItemCoupon['selling_pricemean'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature from customer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerProfileData=c_trans_Data.groupby('customer_id',as_index=False).agg({'quantity':'sum','date':'nunique','item_id':'count',\n",
    "                                                                        'selling_price':{'maxSP':'max','minSP':'min',\n",
    "                                                                                        'averageSP':'mean'},\n",
    "                                                                        'other_discount':{'maxOD':'max','minOD':'min',\n",
    "                                                                                        'averageOD':'mean'},\n",
    "                                                                        'coupon_discount':{'maxCD':'max','minCD':'min',\n",
    "                                                                                        'averageCD':'mean','totalCDAvailed':'count'}})\n",
    "\n",
    "customerProfileData.columns = ['_'.join(col) for col in customerProfileData.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerProfileData.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering on  transaction item data information to get information about coupons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedItemCoupon.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datatoCluster=mergedItemCoupon.groupby('coupon_id',as_index=False).mean()[['coupon_id', \n",
    "       'selling_pricemean', 'coupon_discountdiscountCount',\n",
    "       'coupon_discounttotalDisc', 'other_discountOTdiscountCount',\n",
    "       'other_discountOTtotalDisc', 'dicountPerGiven', 'dicountOthPerGiven',\n",
    "       'dicountGivenPerc', 'dicountOthPerGivenPerc','probaItem']]\n",
    "\n",
    "clusVar=['coupon_id', \n",
    "       'selling_pricemean', 'coupon_discountdiscountCount',\n",
    "       'coupon_discounttotalDisc', 'other_discountOTdiscountCount',\n",
    "       'other_discountOTtotalDisc', 'dicountPerGiven', 'dicountOthPerGiven',\n",
    "       'dicountGivenPerc', 'dicountOthPerGivenPerc','probaItem']\n",
    "\n",
    "from sklearn import preprocessing,cluster,decomposition\n",
    "\n",
    "preProCl=preprocessing.StandardScaler()\n",
    "clusData=preProCl.fit_transform(datatoCluster[clusVar])\n",
    "\n",
    "pcaComp=decomposition.PCA()\n",
    "pcaData=pcaComp.fit_transform(clusData)\n",
    "pcaComp.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaDataFToGraph=pd.DataFrame(pcaData[:,:2],columns=['pca1','pca2'])\n",
    "kM=cluster.KMeans()\n",
    "pcaDataFToGraph['clusCat']=kM.fit_predict(clusData[:,:5])\n",
    "pcaDataFToGraph.head(2)\n",
    "sns.scatterplot(pcaDataFToGraph['pca1'],pcaDataFToGraph['pca2'],hue=pcaDataFToGraph['clusCat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcaDataFToGraph['clusCat']=pcaDataFToGraph['clusCat'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaDataTOCoup=pd.concat([datatoCluster[['coupon_id']],pcaDataFToGraph],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatoCluster.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# crosstabData=pd.pivot_table(coupon_item_mappingData,index='coupon_id',columns='item_id',values='val',aggfunc=np.sum).fillna(0)\n",
    "# coupon_idData=trainCampDatamerge.groupby('coupon_id',as_index=False).agg({'redemption_status':'sum'})\n",
    "# coupon_idData[coupon_idData['redemption_status']>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final data for model prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del datatoCluster['probaItem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X1=pd.merge(allData,coupon_categFind,on='coupon_id',how='left')\n",
    "X2=pd.merge(X1,datatoCluster,on='coupon_id',how='left')\n",
    "X3=pd.merge(X2,pcaDataTOCoup,on='coupon_id',how='left')\n",
    "X4=pd.merge(X3,campData,on='campaign_id',how='left')\n",
    "X5=pd.merge(X4,customer_demographicsData,on='customer_id',how='left')\n",
    "X6=pd.merge(X5,customerProfileData,left_on='customer_id',right_on='customer_id_',how='left')\n",
    "# X2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5['marital_status']=X5['marital_status'].fillna('Other')\n",
    "X5['rented']=X5['rented'].fillna(0)\n",
    "X5['no_of_children']=X5['no_of_children'].fillna('0')\n",
    "X5['age_range']=X5['age_range'].fillna('Other')\n",
    "X5['family_size']=X5['family_size'].fillna('9999')\n",
    "X5['income_bracket']=X5['income_bracket'].fillna(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llP=preprocessing.LabelEncoder()\n",
    "# X5[jj]=llP.fit_transform(X5['campaign_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5[['category', 'clusCat', 'campaign_type', 'no_of_children', 'income_bracket']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X5['no_of_children']=X5['no_of_children'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(X5['family_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categoColumns=[ 'campaign_type','no_of_children','category','brand_type','age_range','marital_status','family_size']\n",
    "# catData=pd.get_dummies(X5[categoColumns],prefix_sep='_',)\n",
    "for jj in categoColumns:\n",
    "    print (jj)\n",
    "    llP=preprocessing.LabelEncoder()\n",
    "    X5[jj]=llP.fit_transform(X5[jj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newtData=pd.concat([X5,catData],sort=False,axis=1)\n",
    "newtData=X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XVar=list(newtData.columns)\n",
    "XVar.remove('id')\n",
    "XVar.remove('redemption_status')\n",
    "XVar.remove('dtType')\n",
    "XVar.remove('start_date')\n",
    "XVar.remove('end_date')\n",
    "YVar='redemption_status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in categoColumns+['campaign_id', 'coupon_id', 'customer_id']:\n",
    "#     XVar.remove(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPart=newtData[newtData['dtType']=='train']\n",
    "testPart=newtData[newtData['dtType']=='test']\n",
    "trainPart.shape,testPart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "XVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection,metrics\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test Split Train, Val, Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,testHX,trainY,testHY=model_selection.train_test_split(trainPart[XVar],trainPart[YVar],test_size=.2,stratify =trainPart[YVar])\n",
    "trainX.shape,testHX.shape,trainY.shape,testHY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX1,valX1,trainY1,valY1=model_selection.train_test_split(trainX,trainY,test_size=.2,stratify =trainY)\n",
    "trainX1.shape,valX1.shape,trainY1.shape,valY1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelR=xgb.XGBClassifier().fit(trainX1,trainY1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=modelR.predict(trainX)\n",
    "t2=modelR.predict(valX1)\n",
    "t3=modelR.predict(testHX)\n",
    "trainScore=modelR.predict_proba(trainX)[:,1]\n",
    "testScore=modelR.predict_proba(valX1)[:,1]\n",
    "test2Score=modelR.predict_proba(testHX)[:,1]\n",
    "\n",
    "print ('train {} vs {} validation {} vs {} test {} vs {}'.format(sum(trainY),sum(t1),sum(valY1),sum(t2), sum(testHY),sum(t3)))\n",
    "metrics.roc_auc_score(trainY,trainScore),metrics.roc_auc_score(valY1,testScore),metrics.roc_auc_score(testHY,test2Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm  as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelL=lgb.LGBMClassifier().fit(trainX1,trainY1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1=modelL.predict(trainX)\n",
    "t2=modelL.predict(valX1)\n",
    "t3=modelL.predict(testHX)\n",
    "trainScore=modelL.predict_proba(trainX)[:,1]\n",
    "testScore=modelL.predict_proba(valX1)[:,1]\n",
    "test2Score=modelL.predict_proba(testHX)[:,1]\n",
    "\n",
    "print ('train {} vs {} validation {} vs {} test {} vs {}'.format(sum(trainY),sum(t1),sum(valY1),sum(t2), sum(testHY),sum(t3)))\n",
    "metrics.roc_auc_score(trainY,trainScore),metrics.roc_auc_score(valY1,testScore),metrics.roc_auc_score(testHY,test2Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRF=ensemble.RandomForestClassifier().fit(trainX1,trainY1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=modelRF.predict(trainX)\n",
    "t2=modelRF.predict(valX1)\n",
    "t3=modelRF.predict(testHX)\n",
    "trainScore=modelRF.predict_proba(trainX)[:,1]\n",
    "testScore=modelRF.predict_proba(valX1)[:,1]\n",
    "test2Score=modelRF.predict_proba(testHX)[:,1]\n",
    "\n",
    "print ('train {} vs {} validation {} vs {} test {} vs {}'.format(sum(trainY),sum(t1),sum(valY1),sum(t2), sum(testHY),sum(t3)))\n",
    "metrics.roc_auc_score(trainY,trainScore),metrics.roc_auc_score(valY1,testScore),metrics.roc_auc_score(testHY,test2Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'base_score':0.9,\n",
    "        'booster':'gbtree', \n",
    "        'colsample_bylevel':1,\n",
    "       'colsample_bytree':1, \n",
    "        'gamma':0, \n",
    "        'learning_rate':0.1, \n",
    "        'max_delta_step':0,\n",
    "       'max_depth':3, \n",
    "        'min_child_weight':1, \n",
    "        'n_estimators':100,\n",
    "        'eval_metric': ['logloss','auc'],\n",
    "       'n_jobs':1,  'objective':'binary:logistic', 'random_state':0,\n",
    "       'reg_alpha':0, 'reg_lambda':1, 'scale_pos_weight':1, 'subsample':1,\n",
    "       'early_stopping_rounds' : 50,\n",
    "       'stratified':True }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_round = 1000\n",
    "\n",
    "dtrain = xgb.DMatrix(trainX1,trainY1)\n",
    "# dtrain.set_group(Xg)\n",
    "\n",
    "dvalid = xgb.DMatrix(valX1, valY1)\n",
    "# dvalid.set_group(Xgt)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "bst = xgb.train(params, dtrain, num_round, evals = watchlist,\n",
    "    early_stopping_rounds=50,verbose_eval=50,maximize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(testHX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testScoreP=bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(testHY,testScoreP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtestOrg = xgb.DMatrix(testPart[XVar])\n",
    "testScoreP2=bst.predict(dtestOrg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testFScore=modelR.predict_proba(testPart[XVar])[:,1]\n",
    "firstSub2=pd.DataFrame(data={'id':test_QyjYwdjData['id'],YVar:testScoreP2})\n",
    "firstSub2.to_csv('firstSub8.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
